{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331cf647-8a52-4ce3-9a85-5d023670ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xmltodict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c29e1-2fcb-40cd-8466-479e6fb5a133",
   "metadata": {},
   "source": [
    "# Get course data from FS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6919a0c9-8e19-45f6-a944-787197a1865d",
   "metadata": {},
   "source": [
    "Documentation of API:\n",
    "  * <https://www.fellesstudentsystem.no/brukersider/teknisk/fsws-dok/soap/studinfo2/studinfo2.pdf>\n",
    "  * <https://www.fellesstudentsystem.no/brukersider/teknisk/fsws-dok/rest/studinfo.html>\n",
    "  \n",
    "URL to use: `https://fsws.usit.no/fsrest/rest/studinfo/<tjeneste>/<query-parametre>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43388e57-4a04-4141-9741-df75ec083086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import json\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import urllib.parse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For parsing xml and docbook\n",
    "import xmltodict\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Find and load the .env file\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b8451-ca34-4278-8090-e0a0d4589bc1",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3679d-6d6a-45c7-8da2-b3af5b2eef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import collections\n",
    "import re\n",
    "\n",
    "def find_pattern(dictionary, pattern, path=''):\n",
    "    \"\"\"Find keys or values in nested dictionary that match a given pattern.\"\"\"\n",
    "    matches = []\n",
    "    for key, value in dictionary.items():\n",
    "        new_path = f\"{path}.{key}\" if path else key\n",
    "        if fnmatch.fnmatch(key, pattern) or (isinstance(value, str) and fnmatch.fnmatch(value, pattern)):\n",
    "            matches.append(new_path)\n",
    "        if isinstance(value, dict):\n",
    "            matches.extend(find_pattern(value, pattern, new_path))\n",
    "        elif isinstance(value, list):\n",
    "            for i, item in enumerate(value):\n",
    "                if isinstance(item, dict):\n",
    "                    matches.extend(find_pattern(item, pattern, f\"{new_path}[{i}]\"))\n",
    "    return matches\n",
    "\n",
    "def get_structure(dictionary, max_depth):\n",
    "    \"\"\"Get the structure of a nested dictionary up to a certain depth.\"\"\"\n",
    "    if max_depth <= 0:\n",
    "        return type(dictionary).__name__\n",
    "    elif isinstance(dictionary, dict):\n",
    "        return {key: get_structure(value, max_depth - 1) for key, value in dictionary.items()}\n",
    "    elif isinstance(dictionary, list):\n",
    "        return [get_structure(item, max_depth - 1) for item in dictionary]\n",
    "    else:\n",
    "        return type(dictionary).__name__\n",
    "\n",
    "\n",
    "\n",
    "def convert_docbook_to_markdown(text):\n",
    "    # Convert <p> tags\n",
    "    text = re.sub(r'<p\\b[^>]*>(.*?)</p>', r'\\n\\1\\n', text)\n",
    "\n",
    "    # Convert <list> tags\n",
    "    text = re.sub(r'<list\\b[^>]*>(.*?)</list>', r'\\n\\1\\n', text)\n",
    "\n",
    "    # Convert <listItem> tags\n",
    "    text = re.sub(r'<listItem\\b[^>]*>(.*?)</listItem>', r'* \\1\\n', text)\n",
    "\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9eeec-d632-439b-83ab-98542bee0d53",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb54c1b-de17-407c-980b-4bfe46f4da62",
   "metadata": {},
   "source": [
    "Configuration of organizations with username and org nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711ada7-d878-4381-8fba-1fdf7b5f48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs = [\n",
    "    {\"name\": \"siktai_aho\", \"instnr\": 189},\n",
    "    {\"name\": \"siktai_ath\", \"instnr\": 255},\n",
    "    {\"name\": \"siktai_bdm\", \"instnr\": 1526},\n",
    "    {\"name\": \"siktai_dmmh\", \"instnr\": 253},\n",
    "    {\"name\": \"siktai_fih\", \"instnr\": 258},\n",
    "    {\"name\": \"siktai_him\", \"instnr\": 211},\n",
    "    {\"name\": \"siktai_hinn\", \"instnr\": 209},\n",
    "    {\"name\": \"siktai_hiø\", \"instnr\": 224},\n",
    "    {\"name\": \"siktai_hvl\", \"instnr\": 203},\n",
    "    {\"name\": \"siktai_hvo\", \"instnr\": 223},\n",
    "    {\"name\": \"siktai_khio\", \"instnr\": 260},\n",
    "    {\"name\": \"siktai_krus\", \"instnr\": 1661},\n",
    "    {\"name\": \"siktai_ldh\", \"instnr\": 230},\n",
    "    {\"name\": \"siktai_mf\", \"instnr\": 190},\n",
    "    {\"name\": \"siktai_mil\", \"instnr\": 1627},\n",
    "    {\"name\": \"siktai_nhh\", \"instnr\": 191},\n",
    "    {\"name\": \"siktai_nih\", \"instnr\": 150},\n",
    "    {\"name\": \"siktai_nla\", \"instnr\": 254},\n",
    "    {\"name\": \"siktai_nmbu\", \"instnr\": 192},\n",
    "    {\"name\": \"siktai_nmh\", \"instnr\": 178},\n",
    "    {\"name\": \"siktai_nord\", \"instnr\": 204},\n",
    "    {\"name\": \"siktai_ntnu\", \"instnr\": 194},\n",
    "    {\"name\": \"siktai_nuc\", \"instnr\": 259},\n",
    "    {\"name\": \"siktai_oslomet\", \"instnr\": 215},\n",
    "    {\"name\": \"siktai_phs\", \"instnr\": 233},\n",
    "    {\"name\": \"siktai_sash\", \"instnr\": 231},\n",
    "    {\"name\": \"siktai_uia\", \"instnr\": 201},\n",
    "    {\"name\": \"siktai_uib\", \"instnr\": 184},\n",
    "    {\"name\": \"siktai_uio\", \"instnr\": 185},\n",
    "    {\"name\": \"siktai_uis\", \"instnr\": 217},\n",
    "    {\"name\": \"siktai_uit\", \"instnr\": 186},\n",
    "    {\"name\": \"siktai_unis\", \"instnr\": 195},\n",
    "    {\"name\": \"siktai_usn\", \"instnr\": 222},\n",
    "    {\"name\": \"siktai_vid\", \"instnr\": 251},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26576d-3f13-4b9c-b5db-b9b74ef986e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139df4b-5fbb-4694-90e1-9f0754b1f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseEmner(emner, orgname, aar):\n",
    "    res = []\n",
    "    columns_to_include = ['infotyper']\n",
    "    for emne in emner:\n",
    "        if isinstance(emne, str):\n",
    "            print(\"Unwexpected value for emne \" + emne)\n",
    "            continue\n",
    "        if 'infotyper' not in emne:\n",
    "            continue\n",
    "        if not isinstance(emne.get('emneid', {}), dict):\n",
    "            print(\"Unwexpected value for emneid \" + emne.get('emneid', {}))\n",
    "            continue\n",
    "        new_item = {\n",
    "            'inst': emne.get('emneid', {}).get('Institusjonsnr', np.nan),\n",
    "            'iname': orgname,\n",
    "            'aar': aar,\n",
    "            'emneid': emne.get('emneid', {}).get('Emnekode', np.nan),\n",
    "            'studiepoeng': emne.get('studiepoeng', np.nan),\n",
    "            'studienivakode': emne.get('studienivakode', np.nan),\n",
    "            'nuskode': emne.get('nuskode', np.nan),\n",
    "            'sprak': emne.get('@sprak', np.nan)\n",
    "        }\n",
    "        for ii in emne['infotyper']:\n",
    "            if ii in ['emneansvar', 'sensorordning', 'undform', 'hjelpemidler', 'vurderingsuttrykk', 'overlapp', 'opptak', 'fagplan', 'arbeidskrav', 'eksamen']:\n",
    "                continue\n",
    "            if 'infotekst' not in emne['infotyper'][ii]:\n",
    "                continue\n",
    "            if not isinstance(emne['infotyper'][ii]['infotekst'], str):\n",
    "                continue\n",
    "            new_item['desc-' + ii] = convert_docbook_to_markdown(emne['infotyper'][ii]['infotekst'])\n",
    "            #new_item['desc-' + ii] = emne['infotyper'][ii]['infotekst']\n",
    "        res.append(new_item)\n",
    "\n",
    "    return pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af6c32-db01-4841-9dda-5c3742c91b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(username, instnr, aar):\n",
    "    password = os.environ.get(\"FS_PASS\")\n",
    "    auth_details = (username, password)\n",
    "    baseURL = \"https://fsws.usit.no/fsrest/rest/studinfo/emne/\"\n",
    "\n",
    "    # FSWS Query\n",
    "    query = {\n",
    "        'institusjonsnr': instnr,\n",
    "        'faknr': '-1',\n",
    "        'instituttnr': '-1',\n",
    "        'gruppenr': '-1',\n",
    "        'arstall': aar,\n",
    "        'terminkode': 'STÅR',\n",
    "        'sprak': 'B', \n",
    "        # can be B, N or E\n",
    "    }\n",
    "    response = requests.get(baseURL + \"?\" + urllib.parse.urlencode(query), auth=auth_details)\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        data_dict = xmltodict.parse(response.text)\n",
    "        if 'fs-studieinfo' in data_dict:\n",
    "            if 'emne' in data_dict['fs-studieinfo']:\n",
    "                return parseEmner(data_dict['fs-studieinfo']['emne'], username, aar)\n",
    "    else:\n",
    "        print(\"HTTP Error:\", response.status_code)\n",
    "        print(\"Error Body:\", response.text)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd179f-4081-4c16-9f92-0ac3efd60033",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for aar in range(2023, 1980, -1):\n",
    "    for org in orgs:\n",
    "        i += 1\n",
    "        if i >= 50:\n",
    "            break\n",
    "        print(f\"Processing {org['name']} {org['instnr']} for {aar}\")\n",
    "        emner = getData(org['name'], org['instnr'], aar)\n",
    "        display(emner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdf7f0-77f3-4d08-a927-92dc8f4ee016",
   "metadata": {},
   "outputs": [],
   "source": [
    "emnr = parseEmner(data_dict['fs-studieinfo']['emne'])\n",
    "emnr\n",
    "#emnr[emnr['desc-innhold'].notna()]\n",
    "#len(emnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f3422-1e8c-4cdc-972a-81f4f096fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'emnr' is the name of your dataframe\n",
    "for index, row in emnr.head(10).iterrows():\n",
    "    #print('-----: ' + row['emneid'])\n",
    "    display(Markdown('-----'))\n",
    "    print(row['desc-utbytte'])\n",
    "    #display(Markdown(convert_docbook_to_markdown(row['desc-utbytte'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a8d2e-ec9e-4d5f-ac25-81997379d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_counts = emnr.isna().sum()\n",
    "\n",
    "print(na_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c6408-e9c2-4d3f-8f3d-9bb96e067775",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = emnr[emnr['infotyper'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce6299-5b1c-4c6e-856f-7b3a43a7cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'emnr' is your DataFrame\n",
    "#for index, row in emnr.iterrows():\n",
    "#    infotyper_value = row['infotyper']\n",
    "\n",
    "print(emnr['infotyper'])\n",
    "get_structure(emnr, 10)\n",
    "x = pd.DataFrame(emnr['infotyper'][0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21632a30-e903-46de-8936-3430a95a433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f19719-27f1-46d9-b867-dfb7b3ddf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_structure(data_dict, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e32461-9451-4bb5-94d9-2104950d7cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
